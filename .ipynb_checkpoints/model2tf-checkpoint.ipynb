{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58643eb8-b5df-47bc-8059-37bba7c402de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92b8c7a-f826-4f11-b70e-bf4345bd3202",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Image.open('sample_images/chicago.jpg')\n",
    "s = Image.open('sample_images/starry.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e45c485-1ba0-4d79-a65f-5ee4ea874443",
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4169cab0-d7a5-4e8b-a8b9-5fa706b17c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bb246e-ad3f-45e5-8bec-1a1c8a7506d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import Stylizer\n",
    "net = Stylizer()\n",
    "net(c,s,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fb2752-13b5-458c-a1df-6e65f625596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.encoder.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f30deb-dd68-4a59-9d79-6f1d86e3b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.model import Encoder, Decoder, get_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a426ba-0582-4db3-91e2-6ee45fca0115",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder().to('cuda')\n",
    "decoder = Decoder().to('cuda')\n",
    "trfm = get_transformer().to('cuda')\n",
    "\n",
    "iters = 1\n",
    "dummy_content = torch.randn(1, 3, 512, 512, device='cuda')\n",
    "dummy_style = torch.randn(1, 3, 512,512, device='cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    c4_1 = dummy_content.detach().clone()\n",
    "    s4_1 = dummy_style.detach().clone()\n",
    "    for _ in range(iters):\n",
    "        out = encoder(c4_1)\n",
    "        \n",
    "        torch.onnx.export(encoder, c4_1, \n",
    "                          'encoder.onnx',\n",
    "                          input_names=['image'],\n",
    "                          output_names=('out4_1','out5_1'),\n",
    "                          opset_version=11\n",
    "                         )\n",
    "        c4_1, c5_1 = out\n",
    "        s4_1, s5_1 = encoder(s4_1)\n",
    "\n",
    "        \n",
    "        c_tfm = trfm(c4_1, s4_1, c5_1, s5_1)\n",
    "        \n",
    "        torch.onnx.export(trfm, (c4_1, s4_1, c5_1, s5_1),\n",
    "                          'transform.onnx',\n",
    "                          input_names=['c4_1', 's4_1', 'c5_1', 's5_1'],\n",
    "                          opset_version=11,\n",
    "                          output_names=('c_tfm',)\n",
    "                         )\n",
    "        \n",
    "        c_stylized = decoder(c_tfm)\n",
    "        \n",
    "        torch.onnx.export(decoder, c_tfm,\n",
    "                         'decoder.onnx',\n",
    "                          input_names=['c_tfm'],\n",
    "                          opset_version=11,\n",
    "                          output_names=('c_stylized',)\n",
    "                         )\n",
    "        \n",
    "        c4_1 = c_stylized.detach().clone()\n",
    "        s4_1 = dummy_style.detach().clone()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# dummy_input = enc_model(dummy_input)\n",
    "\n",
    "# trf_model = net.transform().cuda()\n",
    "\n",
    "\n",
    "# dec_model = net.decoder.cuda()\n",
    "# torch.onnx.export(dec_model,\n",
    "#                   dummy_input,\n",
    "#                   'decoder.onnx', \n",
    "#                   input_names=['encoded'],\n",
    "#                  opset_version=11)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b183241-95b6-42b7-8839-c0a233e0a3e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install onnx-tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e823f3-3f6f-458d-812d-9f0ba776fe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f5b5a-d2d8-429c-9b71-1ca44222de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_onnx(model_path, **kwargs):\n",
    "    kwargs = {k:np.array(v) for k,v in kwargs.items()}\n",
    "    out = ort.InferenceSession(model_path)\\\n",
    "        .run(None,input_feed=kwargs)    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a862356f-89ef-41ef-8e58-4c71c1ead16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = T.RandomCrop((512,512),pad_if_needed=True,padding_mode='reflect')\n",
    "resize = T.Resize((512,512))\n",
    "batch_dim = T.Lambda(lambda x:x[None,...])\n",
    "to_tensor = T.ToTensor()\n",
    "\n",
    "content_tfm = T.Compose((resize, to_tensor, batch_dim))\n",
    "style_tfm = T.Compose((resize, to_tensor, batch_dim))\n",
    "\n",
    "iters = 2\n",
    "c_inp =content_tfm(c)\n",
    "s_inp =style_tfm(s)\n",
    "\n",
    "with torch.no_grad():\n",
    "    c4_1 = c_inp.detach().clone()\n",
    "    s4_1 = s_inp.detach().clone()\n",
    "    for _ in range(iters):\n",
    "        c4_1, c5_1 = run_onnx('encoder.onnx', image=c4_1)\n",
    "        s4_1, s5_1 = run_onnx('encoder.onnx', image=s4_1)\n",
    "        (c_tfm,) = run_onnx('transform.onnx', c4_1=c4_1,\n",
    "                         s4_1=s4_1, c5_1=c5_1, s5_1=s5_1)\n",
    "        (c_stylized,) = run_onnx('decoder.onnx', c_tfm=c_tfm)\n",
    "        c4_1 = c_stylized#.detach().clone()\n",
    "        s4_1 = s_inp#.detach().clone()\n",
    "        c4_1 = c4_1.clip(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b125851-f943-40bb-a811-2e8c29f9adcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(c4_1.transpose(0,2,3,1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6033af25-c1ab-40b8-b9ab-e87ded66376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_files = ['decoder.onnx','encoder.onnx','transform.onnx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedc7d70-c490-48e6-aade-c65364419383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from onnx_tf.backend import prepare\n",
    "tf_files = []\n",
    "for file in model_files:\n",
    "    print(f'converting {file}')\n",
    "    onnx_model = onnx.load(file)  # load onnx model\n",
    "    tf_rep = prepare(onnx_model)  # prepare tf representation\n",
    "    tf_model_path = f\"tf_models/{Path(file).stem}\"\n",
    "    tf_rep.export_graph(tf_model_path)  # export the model\n",
    "    tf_files.append(tf_model_path)\n",
    "    # !onnx-tf convert -i {file} -o {Path(file).stem + '.tf2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f08ca98-c0dc-417a-ae30-36bb9621e833",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install tensorflowjs[wizard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8184e281-a54a-400f-872b-92bf5aba3ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tf_file in tf_files:\n",
    "    js_file = f'js_models/{Path(tf_file).stem}'\n",
    "    !tensorflowjs_converter \\\n",
    "        --input_format=tf_saved_model \\\n",
    "        --output_format=tfjs_graph_model \\\n",
    "        {tf_file} \\\n",
    "        {js_file}\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
